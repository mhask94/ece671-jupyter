{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](table_of_contents.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 20.  Eigenvalues and Eigenvectors\n",
    "Author: Mat Haskell - mhaskell9@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Introduction\n",
    "Eigen values and eigen vectors are very cool and show up all over the place. Eigenvalues exist generally for linear operators, but this notebook will just look at matrices. The basic idea is that matrix multiplication is turned into scalar multiplication. This seems strange since matrix multiplication is complex and you can't always envision the result by just looking at the equation. Matrices can be used to project onto a lower dimensional space and rotate a vector, which is how they are commonly used. However, when multiplying a matrix by one of its eigenvectors, that vector will just be scaled by the value of the corresponding eigenvalue. The eigenvector can grow, shrink, and flip directions (i.e. eigenvalues can be negative). Eigenvalues can even be zero, in which case the eigenvector multiplied by the matrix will be scaled down to zero as well.\n",
    "\n",
    "preface this\n",
    "The physical meaning of eigenvalues and eigenvectors is also cool. The eigenvectors are the principal axes of the matrix. This means that the eigenvectors of a stress/strain tensor are the principal axes and the eigenvalues are the principal stresses/strains. Another example is with an inertia tensor. If there are cross terms (elements off the main diagonal in the inertia tensor) the eigenvectors are the axes of the object that get rid of the cross terms. This means you can find the x, y, and z axes where there is symmetry and no inertia in any other direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\real}{\\mathbb{R}}$\n",
    "$\\newcommand{\\complex}{\\mathbb{C}}$\n",
    "$\\newcommand{\\script}[1]{\\mathcal{#1}}$\n",
    "## Explanation of the theory\n",
    "Eigenvalues only exist for square matrices.\n",
    "$$A\\in \\complex^{n\\times n}$$\n",
    "\n",
    "Let $x\\in\\complex^{n\\times1}$ be an eigenvector of A and $\\lambda\\in\\complex$ be the corresponding eigenvalue of A, then converting matrix multiplication into scalar multiplication yields the equation:\n",
    "$$Ax=\\lambda x$$\n",
    "\n",
    "\n",
    "__Def:__ $(\\lambda,x)$ is a __right eigen pair__ if $Ax=\\lambda x$.\n",
    "\n",
    "__Def:__ $(\\lambda,x)$ is a __left eigen pair__ if $x^HA^H=\\lambda x^H$.\n",
    "\n",
    "Most of the time we deal with right eigen pairs. So here is how to actually solve for the eigenvalues.\n",
    "\n",
    "1. Get everything onto 1 side of the equation (it doesn't matter which side):\n",
    "\n",
    "$$Ax-\\lambda x=0$$\n",
    "\n",
    "2. Multiply x by identity (which doesn't change it):\n",
    "\n",
    "$$Ax-\\lambda Ix=0$$\n",
    "\n",
    "3. Factor out the x\n",
    "\n",
    "$$(A-\\lambda I)x=0$$\n",
    "\n",
    "4. Since $x\\in\\mathcal{N}(A-\\lambda I)$, we know that $(A-\\lambda I)$ is not full rank, which implies that its determinant equals 0:\n",
    "\n",
    "$$det(A-\\lambda I)=0$$\n",
    "\n",
    "$$\n",
    "\\Rightarrow\n",
    "\\left|\n",
    "\\begin{pmatrix}\n",
    "a_{11} & a_{12} & \\cdots & a_{1n}\\\\\n",
    "a_{21} & a_{22} & \\cdots & a_{2n}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "a_{n1} & a_{n2} & \\cdots & a_{nn}\n",
    "\\end{pmatrix}\n",
    "-\n",
    "\\begin{pmatrix}\n",
    "\\lambda & 0 & \\cdots & 0\\\\\n",
    "0 & \\lambda & \\cdots & 0\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "0 & 0 & \\cdots & \\lambda\n",
    "\\end{pmatrix}\n",
    "\\right|\n",
    "=0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Rightarrow\n",
    "\\left|\n",
    "\\begin{pmatrix}\n",
    "a_{11}-\\lambda & a_{12} & \\cdots & a_{1n}\\\\\n",
    "a_{21} & a_{22}-\\lambda & \\cdots & a_{2n}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "a_{n1} & a_{n2} & \\cdots & a_{nn}-\\lambda\n",
    "\\end{pmatrix}\n",
    "\\right|\n",
    "=0\n",
    "$$\n",
    "\n",
    "5. Taking the determinant will give the characteristic polynomial, $\\chi_A(\\lambda)$, and characteristic equation, \n",
    "$\\chi_A(\\lambda)=0$:\n",
    "\n",
    "$$\\chi_A(\\lambda)\\triangleq\\lambda^n+\\alpha_{n-1}\\lambda^{n-1}+\\cdots+\\alpha_1\\lambda+\\alpha_0=0$$\n",
    "\n",
    "6. The roots of the characteristic polynomial are the eigenvalues. By the fundamental theorem of algebra, we know that the characteristic polynomial will have n roots. This means that there are going to be n eigenvalues, although some of them may be repeated. Solve for the roots. Note: we can rearrange the characteristic equation to look like this:\n",
    "\n",
    "$$\\chi_A(\\lambda)=(\\lambda-\\lambda_{1})(\\lambda-\\lambda_{2})\\cdots(\\lambda-\\lambda_{n})$$\n",
    "\n",
    "__Def:__ Algebraic multiplicity, $m_i$, of $\\lambda_i$ is the number of times it is repeated.\n",
    "$$\\chi_A(\\lambda)=(\\lambda-\\lambda_{1})^{m_1}(\\lambda-\\lambda_{2})^{m_2}\\cdots(\\lambda-\\lambda_{p})^{m_p},\\ \\ \\ \\ \\ p\\leq n$$\n",
    "\n",
    "After finding the roots/eigenvalues, we can solve for the eigenvectors by plugging in each eigenvalue into the equation $(A-\\lambda_iI)x=0$. You are just solving for the null space of $(A-\\lambda I)$. Note that any linear combination of vectors from $\\mathcal{N}(A-\\lambda I)$ are also eigenvectors. Since any scalar multiple of an eigenvector is also an eigenvector, most software libraries will return the eigenvectors with a norm of 1.\n",
    "\n",
    "Note: If eigenvalues are complex, the corresponding eigenvectors will be complex. When eigenvalues are complex, both complex numbers from the complex conjugate pair will be eigenvalues. Similarly for eigenvectors: if an eigenvector is complex, its complex conjugate will also be an eigenvector.\n",
    "\n",
    "__Def:__ Geometric multiplicity, $q_i$, of $\\lambda_i$ is the number of linearly independent eigenvectors that can be formed from $\\lambda_i$. Also, $$1\\leq q_i\\leq m_i$$\n",
    "This means at least 1 eigenvector can be formed from every eigenvalue. For example: if an eigenvalue is repeated 3 times, there will be at most 3 corresponding linearly independent eigenvectors but at least 1 eigenvector.\n",
    "\n",
    "\n",
    "Can also add these concepts:\n",
    "- Symmetric matrices have real eigenvalues\n",
    "- Eigenvalue decomposition $S\\Lambda S^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Numerical Examples\n",
    "\n",
    "Provide some simple python code and examples that emphasize the basic concepts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues are 11, 1, and 2.\n",
      "The eigenvector corresponding to 11 is:\n",
      "[[ 0.        ]\n",
      " [ 0.4472136 ]\n",
      " [ 0.89442719]]\n",
      "The eigenvector corresponding to 1 is:\n",
      "[[ 0.        ]\n",
      " [ 0.89442719]\n",
      " [-0.4472136 ]]\n",
      "The eigenvector corresponding to 2 is:\n",
      "[[ 1.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "success\n",
      "fail\n",
      "success\n",
      "A - S*Lambda*S_inv = \n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   4.44089210e-16   0.00000000e+00]\n",
      " [  0.00000000e+00   4.44089210e-16   0.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  0.,  0.],\n",
       "       [ 0.,  3.,  4.],\n",
       "       [ 0.,  4.,  9.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[2.,0.,0.],\n",
    "              [0.,3.,4.],\n",
    "              [0.,4.,9.]])\n",
    "\n",
    "vals,vecs = np.linalg.eig(A)\n",
    "\n",
    "print('Eigenvalues are %d, %d, and %d.' % (vals[0],vals[1],vals[2]))\n",
    "print('The eigenvector corresponding to %d is:'%vals[0])\n",
    "print(vecs[:,0][:,None])\n",
    "print('The eigenvector corresponding to %d is:'%vals[1])\n",
    "print(vecs[:,1][:,None])\n",
    "print('The eigenvector corresponding to %d is:'%vals[2])\n",
    "print(vecs[:,2][:,None])\n",
    "\n",
    "# check if Ax-lx=0\n",
    "if np.array_equal(A@vecs[:,0], vals[0]*vecs[:,0]) :\n",
    "    print('success')\n",
    "else:\n",
    "    print('fail')\n",
    "if np.array_equal(A@vecs[:,1], vals[1]*vecs[:,1]) :\n",
    "    print('success')\n",
    "else:\n",
    "    print('fail')\n",
    "if np.array_equal(A@vecs[:,2], vals[2]*vecs[:,2]) :\n",
    "    print('success')\n",
    "else:\n",
    "    print('fail')\n",
    "    \n",
    "# A@vecs[:,1] - vals[1]*vecs[:,1]\n",
    "\n",
    "# Eigenvalue decomposition\n",
    "S = vecs\n",
    "Lambda = np.diag([vals[0],vals[1],vals[2]])\n",
    "S_inv = np.linalg.inv(S)\n",
    "\n",
    "# Check that A = S*Lambda*S_inv\n",
    "print('A - S*Lambda*S_inv = ')\n",
    "print(A - S@Lambda@S_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Engineering Application\n",
    "Ideas\n",
    "- Inertia tensor, find axes where there are no cross terms\n",
    "- Differential equation or difference equation (poles of the system show response)\n",
    "- Rotation matrix (eigenvalues will be 1, $e^{j\\theta}$, $e^{-j\\theta}$ and eigenvector corresponding to 1 is the axis of rotation)\n",
    "\n",
    "Provide a more sophisticated example showing one engineering example of the topic, complete with python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
